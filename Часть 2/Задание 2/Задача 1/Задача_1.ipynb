{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c83081",
   "metadata": {},
   "source": [
    "# Богданов Александр Иванович, Б05-003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d681a",
   "metadata": {},
   "source": [
    "## Распознавания именованных сущностей на основе fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c75aa580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:45.566609Z",
     "start_time": "2024-05-09T00:47:45.562818Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from nerus import load_nerus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ec2de4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:45.778083Z",
     "start_time": "2024-05-09T00:47:45.770635Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb22db6",
   "metadata": {},
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d86f0e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:46.148464Z",
     "start_time": "2024-05-09T00:47:46.139936Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sent_tags(docs, size=10000):\n",
    "    list_of_sent = []\n",
    "    list_of_tags = []\n",
    "    for doc in tqdm(docs):\n",
    "        for sent in doc.sents:\n",
    "            list_of_sent_toks = []\n",
    "            list_of_sent_tags = []\n",
    "            for tok in sent.tokens:\n",
    "                list_of_sent_toks.append(tok.text)\n",
    "                list_of_sent_tags.append(tok.pos)\n",
    "        list_of_sent.append(list_of_sent_toks)\n",
    "        list_of_tags.append(list_of_sent_tags)\n",
    "        if len(list_of_sent) > size:\n",
    "            break\n",
    "    return list_of_sent, list_of_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2cdbabaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:46.302071Z",
     "start_time": "2024-05-09T00:47:46.293698Z"
    }
   },
   "outputs": [],
   "source": [
    "def pos_dict(list_of_tags, test_size=100):\n",
    "    pos2idx = {'<PAD>' : 0}\n",
    "    idx2pos = ['<PAD>']\n",
    "\n",
    "    for tags in list_of_tags[:-test_size]:\n",
    "        for word in tags:\n",
    "            if word not in pos2idx:\n",
    "                pos2idx[word] = len(idx2pos)\n",
    "                idx2pos.append(word)\n",
    "    return pos2idx, idx2pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9cc92ded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:46.470003Z",
     "start_time": "2024-05-09T00:47:46.462545Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_dict(list_of_tags, test_size=100):\n",
    "    word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    idx2word = ['<PAD>', '<UNK>']\n",
    "    \n",
    "    for sent in list_of_sent[:-test_size]:\n",
    "        for word in sent:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(idx2word)\n",
    "                idx2word.append(word)\n",
    "                \n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bbb6e142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:46.645763Z",
     "start_time": "2024-05-09T00:47:46.638903Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_matrix_fasttext(tf):\n",
    "\n",
    "    matrix_fasttext = []\n",
    "    \n",
    "    for i, w in enumerate(tqdm(ft.get_words(on_unicode_error='replace'))):\n",
    "        matrix_fasttext.append(ft.get_word_vector(w))\n",
    "        \n",
    "    for w in ['<PAD>', '<UNK>', '<CLS>', '<SEP>']:\n",
    "        matrix_fasttext.append(np.zeros_like(matrix_fasttext[-1]))\n",
    "                \n",
    "    return matrix_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ddaf96bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:46.848241Z",
     "start_time": "2024-05-09T00:47:46.836181Z"
    }
   },
   "outputs": [],
   "source": [
    "class NerusDataset(Dataset):\n",
    "    def __init__(self, list_of_sent, list_of_tags, word2idx, pos2idx, train=True, test_size=100):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        \n",
    "        if train:\n",
    "            for sent in list_of_sent[:-test_size]:\n",
    "                data = []\n",
    "                for word in sent:\n",
    "                    data.append(word2idx.get(word, 0))\n",
    "                self.X.append(data)\n",
    "            \n",
    "            for tags in list_of_tags[:-test_size]:\n",
    "                data = []\n",
    "                for word in tags:\n",
    "                    data.append(pos2idx.get(word, 0))\n",
    "                self.y.append(data)\n",
    "        else:\n",
    "            for sent in list_of_sent[-test_size:]:\n",
    "                data = []\n",
    "                for word in sent:\n",
    "                    data.append(word2idx.get(word, 0))\n",
    "                self.X.append(data)\n",
    "                \n",
    "            for tags in list_of_tags[-test_size:]:\n",
    "                data = []\n",
    "                for word in tags:\n",
    "                    data.append(pos2idx.get(word, 0))\n",
    "                self.y.append(data)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.X[idx]), torch.Tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "32bb7ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:47.089604Z",
     "start_time": "2024-05-09T00:47:47.080391Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    X, Y = [], []\n",
    "    for x, y in data:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_batch = torch.zeros((len(X), max(list(map(len, X)))), dtype=torch.long)\n",
    "    y_batch = torch.zeros((len(Y), max(list(map(len, Y)))), dtype=torch.long)\n",
    "    \n",
    "    for i, sent in enumerate(X):\n",
    "        x_batch[i, :len(sent)] = sent\n",
    "\n",
    "    for i, sent in enumerate(Y):\n",
    "        y_batch[i, :len(sent)] = sent\n",
    "        \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ebc039d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:51:10.805356Z",
     "start_time": "2024-05-09T00:51:10.794924Z"
    }
   },
   "outputs": [],
   "source": [
    "def check(batch_size, dataset, model, loss_function, idx2word, idx2pos):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "            \n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    count = 0\n",
    "    for i, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "        x_batch = x_batch.to(model.device)\n",
    "        y_batch = y_batch.to(model.device)\n",
    "                \n",
    "        mask = (y_batch != 0)\n",
    "        count += mask.sum()\n",
    "                \n",
    "        output = model(x_batch)\n",
    "\n",
    "        test_loss += loss_function(output.transpose(1,2), y_batch).cpu().item()*len(x_batch)\n",
    "        test_acc += (torch.argmax(output, dim=-1).cpu() == y_batch)[mask].sum().item()\n",
    "            \n",
    "    test_loss /= len(dataset)\n",
    "    test_acc /= count\n",
    "\n",
    "    print(f'loss: {test_loss}, acc: {test_acc}')\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    x, y = next(iter(dataloader))\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    outputs = model(x)\n",
    "    \n",
    "    one_x = x[0].cpu().numpy()\n",
    "    one_y = y[0].cpu().numpy()\n",
    "    one_output = outputs[0].argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    words = [idx2word[idx] for idx in one_x]\n",
    "    true_tags = [idx2pos[idx] for idx in one_y]\n",
    "    pred_tags = [idx2pos[idx] for idx in one_output]\n",
    "\n",
    "    table = PrettyTable([\"Word\", \"True tag\", \"Predicted tag\"])\n",
    "    table.align[\"Word\"], table.align[\"True tag\"], table.align[\"Predicted tag\"] = \"l\", \"l\", \"l\"\n",
    "\n",
    "    for word, true_tag, pred_tag in zip(words, true_tags, pred_tags):\n",
    "        if word != idx2word[word2idx['<PAD>']]:\n",
    "            table.add_row([word, true_tag, pred_tag])\n",
    "\n",
    "    print(table)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2e409b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:47.675307Z",
     "start_time": "2024-05-09T00:47:47.666975Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    output = model(x_batch.to(device))\n",
    "    \n",
    "    loss = loss_function(output.transpose(1, 2), y_batch.to(device))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ae7f205c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:47.962978Z",
     "start_time": "2024-05-09T00:47:47.954489Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_generator, model, loss_function, optimizer, callback = None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x.to(device), batch_of_y.to(device), optimizer, loss_function)\n",
    "        train_generator.set_postfix({'train batch loss': batch_loss})\n",
    "        \n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "            \n",
    "        epoch_loss += batch_loss*len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "    \n",
    "    return epoch_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "916d7665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:48.519061Z",
     "start_time": "2024-05-09T00:47:48.508805Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch, \n",
    "            batch_size, \n",
    "            dataset,\n",
    "            model, \n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr = 0.001,\n",
    "            callback = None):\n",
    "\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    \n",
    "    iterations = tqdm(range(count_of_epoch), desc='epoch')\n",
    "    iterations.set_postfix({'train epoch loss': np.nan})\n",
    "    for it in iterations:\n",
    "        batch_generator = tqdm(\n",
    "            torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn), \n",
    "            leave=False, total=len(dataset)//batch_size+(len(dataset)%batch_size> 0))\n",
    "        \n",
    "        epoch_loss = train_epoch(\n",
    "                    train_generator=batch_generator, \n",
    "                    model=model, \n",
    "                    loss_function=loss_function, \n",
    "                    optimizer=optima, \n",
    "                    callback=callback)\n",
    "        \n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "97269029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:47:49.162630Z",
     "start_time": "2024-05-09T00:47:49.147535Z"
    }
   },
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, dataset, loss_function, delimeter = 300, batch_size=64):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        model.eval()\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar('LOSS/train', loss, self.step)\n",
    "        \n",
    "        if self.step % self.delimeter == 0:\n",
    "            \n",
    "            batch_generator = torch.utils.data.DataLoader(dataset=self.dataset, \n",
    "                                                          batch_size=self.batch_size,\n",
    "                                                          collate_fn=collate_fn)\n",
    "            \n",
    "            test_acc = 0\n",
    "            test_loss = 0\n",
    "            count = 0\n",
    "            for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "                x_batch = x_batch.to(model.device)\n",
    "                y_batch = y_batch.to(model.device)\n",
    "                \n",
    "                mask = (y_batch != 0)\n",
    "                count += mask.sum()\n",
    "                \n",
    "                output = model(x_batch)\n",
    "\n",
    "                test_loss += self.loss_function(output.transpose(1,2), y_batch).cpu().item()*len(x_batch)\n",
    "\n",
    "                test_acc += (torch.argmax(output, dim=-1).cpu() == y_batch)[mask].sum().item()\n",
    "            \n",
    "            test_loss /= len(self.dataset)\n",
    "            test_acc /= count\n",
    "\n",
    "            print(f\"\\t step={self.step}, train_loss={loss}, val_loss={test_loss}, val_acc={test_acc}\")\n",
    "            \n",
    "            self.writer.add_scalar('LOSS/test', test_loss, self.step)\n",
    "            self.writer.add_scalar('ACC/test', test_acc, self.step)\n",
    "          \n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e40414",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "663b2dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:42:02.879927Z",
     "start_time": "2024-05-09T00:42:02.871734Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "    def __init__(self,\n",
    "                 vocab_dim,\n",
    "                 output_dim = 12,\n",
    "                 emb_dim = 300, \n",
    "                 hidden_dim = 10,\n",
    "                 num_layers = 3,\n",
    "                 dropout = 0.7,\n",
    "                 batch_norm = True):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(vocab_dim, emb_dim, padding_idx=0)\n",
    "        self.encoder = torch.nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        if batch_norm:\n",
    "            self.batch_norm = torch.nn.BatchNorm1d(hidden_dim)\n",
    "        else:\n",
    "            self.batch_norm = None\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.embedding(input)\n",
    "        out, _ = self.encoder(out)\n",
    "        if self.batch_norm is not None:\n",
    "            out = self.batch_norm(out.transpose(1, 2)).transpose(1, 2)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f0d99",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5935d8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:37:07.787700Z",
     "start_time": "2024-05-09T00:37:07.782711Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = load_nerus(\"nerus_lenta.conllu.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "da274ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:10:05.801416Z",
     "start_time": "2024-05-09T01:10:00.401685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5a828da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:10:11.592123Z",
     "start_time": "2024-05-09T01:10:05.806146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41866c657517466cb1a0caf15663d930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_sent, list_of_tags = get_sent_tags(docs, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0dc7e8f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:10:11.601510Z",
     "start_time": "2024-05-09T01:10:11.592904Z"
    }
   },
   "outputs": [],
   "source": [
    "pos2idx, idx2pos = pos_dict(list_of_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8957c9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:10:26.079395Z",
     "start_time": "2024-05-09T01:10:11.602651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9cb12b735f4b0eba8140f4f887f18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix_fasttext = get_matrix_fasttext(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "588db822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:10:26.097324Z",
     "start_time": "2024-05-09T01:10:26.081141Z"
    }
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = word_dict(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d5177c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:10:26.226126Z",
     "start_time": "2024-05-09T01:10:26.098078Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = NerusDataset(list_of_sent, list_of_tags, word2idx, pos2idx, train=True)\n",
    "test_data = NerusDataset(list_of_sent, list_of_tags, word2idx, pos2idx, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea5f7d0",
   "metadata": {},
   "source": [
    "## Подключим tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f9a3bee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T02:15:17.296296Z",
     "start_time": "2024-05-09T02:15:17.285081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 60721), started 0:00:03 ago. (Use '!kill 60721' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-46f9de2a192dd2dd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-46f9de2a192dd2dd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tensorboard_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3d600",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2174c630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T02:15:21.066449Z",
     "start_time": "2024-05-09T02:15:21.063101Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e90e1106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T02:16:00.442712Z",
     "start_time": "2024-05-09T02:15:21.468109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(2000004, 300, padding_idx=0)\n",
       "  (encoder): LSTM(300, 10, num_layers=3, batch_first=True, dropout=0.7)\n",
       "  (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=10, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(vocab_dim=len(matrix_fasttext), output_dim=len(pos2idx))\n",
    "model.embedding.weight.data.copy_(torch.tensor(matrix_fasttext))\n",
    "for param in model.embedding.parameters():\n",
    "    param.requires_grad = False\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aaea36f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T02:16:54.816430Z",
     "start_time": "2024-05-09T02:16:00.444877Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.8875919914245607, acc: 0.0\n",
      "+--------------------+----------+---------------+\n",
      "| Word               | True tag | Predicted tag |\n",
      "+--------------------+----------+---------------+\n",
      "| Он                 | PRON     | <PAD>         |\n",
      "| призвал            | VERB     | <PAD>         |\n",
      "| бороться           | VERB     | <PAD>         |\n",
      "| с                  | ADP      | <PAD>         |\n",
      "| мздоимством        | NOUN     | <PAD>         |\n",
      "| ,                  | PUNCT    | <PAD>         |\n",
      "| нанося             | VERB     | <PAD>         |\n",
      "| удары              | NOUN     | <PAD>         |\n",
      "| «                  | PUNCT    | <PAD>         |\n",
      "| и                  | CCONJ    | <PAD>         |\n",
      "| по                 | ADP      | <PAD>         |\n",
      "| тигру              | NOUN     | <PAD>         |\n",
      "| ,                  | PUNCT    | <PAD>         |\n",
      "| и                  | CCONJ    | <PAD>         |\n",
      "| по                 | ADP      | <PAD>         |\n",
      "| мухе               | NOUN     | <PAD>         |\n",
      "| »                  | PUNCT    | <PAD>         |\n",
      "| ,                  | PUNCT    | <PAD>         |\n",
      "| то                 | PRON     | <PAD>         |\n",
      "| есть               | VERB     | <PAD>         |\n",
      "| не                 | PART     | <PAD>         |\n",
      "| щадя               | VERB     | <PAD>         |\n",
      "| ни                 | CCONJ    | <PAD>         |\n",
      "| мелких             | ADJ      | <PAD>         |\n",
      "| ,                  | PUNCT    | <PAD>         |\n",
      "| ни                 | CCONJ    | <PAD>         |\n",
      "| высокопоставленных | ADJ      | <PAD>         |\n",
      "| чиновников         | NOUN     | <PAD>         |\n",
      "| .                  | PUNCT    | <PAD>         |\n",
      "+--------------------+----------+---------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df608dc9feff4acdaeb4df9a39b8f660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=300, train_loss=1.9143242835998535, val_loss=1.9298494005203246, val_acc=0.3870220184326172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=600, train_loss=1.6940072774887085, val_loss=1.8164882040023804, val_acc=0.4154113531112671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=900, train_loss=1.6826220750808716, val_loss=1.6774484634399414, val_acc=0.4779837727546692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=1200, train_loss=1.561474323272705, val_loss=1.6148735475540161, val_acc=0.5196987390518188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=1500, train_loss=1.5243782997131348, val_loss=1.5608360052108765, val_acc=0.5260718464851379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=1800, train_loss=1.4919233322143555, val_loss=1.57381441116333, val_acc=0.5376592874526978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=2100, train_loss=1.4440556764602661, val_loss=1.575224094390869, val_acc=0.5469292998313904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=2400, train_loss=1.4258780479431152, val_loss=1.6800995445251465, val_acc=0.5521436929702759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=2700, train_loss=1.3678654432296753, val_loss=1.692449049949646, val_acc=0.5463499426841736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t step=3000, train_loss=1.3479853868484497, val_loss=1.7745773029327392, val_acc=0.5469292998313904\n",
      "loss: 1.8341864824295044, acc: 0.5498261451721191\n",
      "+------------+----------+---------------+\n",
      "| Word       | True tag | Predicted tag |\n",
      "+------------+----------+---------------+\n",
      "| Он         | PRON     | NOUN          |\n",
      "| подлетел   | VERB     | NOUN          |\n",
      "| к          | ADP      | ADP           |\n",
      "| планете    | NOUN     | NOUN          |\n",
      "| на         | ADP      | ADP           |\n",
      "| расстоянии | NOUN     | NOUN          |\n",
      "| около      | ADP      | NOUN          |\n",
      "| 203        | NUM      | NOUN          |\n",
      "| тысяч      | NOUN     | NOUN          |\n",
      "| километров | NOUN     | NOUN          |\n",
      "| (          | PUNCT    | PUNCT         |\n",
      "| примерно   | ADV      | VERB          |\n",
      "| половина   | NOUN     | NOUN          |\n",
      "| расстояния | NOUN     | NOUN          |\n",
      "| до         | ADP      | ADP           |\n",
      "| Луны       | PROPN    | NOUN          |\n",
      "| )          | PUNCT    | CCONJ         |\n",
      "| .          | PUNCT    | PUNCT         |\n",
      "+------------+----------+---------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.8341864824295044, tensor(0.5498))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=f'tensorboard_1/experiment')\n",
    "call = callback(writer, test_data, loss_function)\n",
    "    \n",
    "check(64, test_data, model, loss_function, idx2word, idx2pos)\n",
    "trainer(count_of_epoch=20, \n",
    "        batch_size=64, \n",
    "        dataset=train_data,\n",
    "        model=model, \n",
    "        loss_function=loss_function,\n",
    "        optimizer = optimizer,\n",
    "        callback=call)\n",
    "check(64, test_data, model, loss_function, idx2word, idx2pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cad20",
   "metadata": {},
   "source": [
    "Качество классфикации достаточно хорошее - мы используем не очень большой датасет, не очень сложную архитектуру и небольшое количество эпох, мы видим, что FastText играет существенную роль: FastText создает эмбендинги слов, которые хорошо учитывают отношения между словами."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
